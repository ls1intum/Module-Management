services:
  nginx:
    image: nginx:1.29.4
    container_name: module-management-nginx
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
      - /var/lib/rbg-cert/live/fullchain.pem:/etc/certs/fullchain.pem:ro
      - /var/lib/rbg-cert/live/privkey.pem:/etc/certs/privkey.pem:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - client
      - server
    networks:
      - module-management-network
    restart: unless-stopped

  postgres:
    image: postgres:17.6
    container_name: module-management-db
    environment:
      - "POSTGRES_DB=${DB_NAME}"
      - "POSTGRES_PASSWORD=${DB_PASSWORD}"
      - "POSTGRES_USER=${DB_USER}"
    ports:
      - "${DB_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - module-management-network
    restart: unless-stopped

  text-embeddings-inference:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-latest
    container_name: module-management-tei
    pull_policy: always
    command:
      - --model-id
      - onnx-community/embeddinggemma-300M-ONNX
      - --pooling
      - mean
      - --dtype
      - float32
      - --auto-truncate
    volumes:
      - hf_cache:/data
    ports:
      - "1234:80"
    networks:
      - module-management-network
    restart: unless-stopped

  server:
    image: ghcr.io/ls1intum/module-management/server:${IMAGE_TAG}
    container_name: module-management-server
    depends_on:
      - postgres
      - text-embeddings-inference
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/ModuleManagement
      - SPRING_DATASOURCE_USERNAME=${DB_USER}
      - SPRING_DATASOURCE_PASSWORD=${DB_PASSWORD}
      - SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_JWK-SET-URI=${KEYCLOAK_URL}/realms/${KEYCLOAK_REALM}/protocol/openid-connect/certs
      - SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_ISSUER-URI=${KEYCLOAK_URL}/realms/${KEYCLOAK_REALM}
      - AZURE_API_KEY=${AZURE_API_KEY}
      - AZURE_ENDPOINT=${AZURE_ENDPOINT}
      - AZURE_DEPLOYMENT_NAME=${AZURE_DEPLOYMENT_NAME}
      - EMBEDDING_MODEL_URL=http://text-embeddings-inference:80
      - EMBEDDING_MODEL_NAME=onnx-community/embeddinggemma-300M-ONNX
      - CHAT_MODEL_SOURCE=AzureOpenAiChatModel
      - EMBEDDING_MODEL_SOURCE=OpenAiEmbeddingModel
    volumes:
      - embeddings_cache:/app/data/cache
    networks:
      - module-management-network
    restart: unless-stopped

  client:
    image: ghcr.io/ls1intum/module-management/client:${IMAGE_TAG}
    container_name: module-management-client
    depends_on:
      - server
    networks:
      - module-management-network
    restart: unless-stopped

volumes:
  postgres_data:
  hf_cache:
  embeddings_cache:

networks:
  module-management-network:
    driver: bridge
